{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Minedojo Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:minedojo.tasks] Loaded 1572 Programmatic tasks, 1558 Creative tasks, and 1 special task: \"Playthrough\". Totally 3131 tasks loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Reloader 0\n",
      "ThreadID: 0 has received an enviornment from queue. Reset of environement is being prepeared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:minedojo.tasks] Loaded 1572 Programmatic tasks, 1558 Creative tasks, and 1 special task: \"Playthrough\". Totally 3131 tasks loaded.\n",
      "[INFO:minedojo.tasks] Loaded 1572 Programmatic tasks, 1558 Creative tasks, and 1 special task: \"Playthrough\". Totally 3131 tasks loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThreadID 0 put complete environment into ready-queue.\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[[ 34,  38,  41, ...,  45,  41,  38],\n        [ 37,  40,  44, ...,  48,  45,  41],\n        [ 40,  44,  48, ...,  51,  48,  44],\n        ...,\n        [ 61,  64,  68, ...,  67,  70,  66],\n        [ 58,  61,  65, ...,  64,  61,  64],\n        [ 56,  59,  62, ...,  62,  58,  61]],\n\n       [[ 40,  45,  48, ...,  53,  49,  45],\n        [ 44,  47,  52, ...,  56,  53,  48],\n        [ 47,  51,  56, ...,  60,  56,  52],\n        ...,\n        [ 71,  76,  80, ...,  42,  44,  42],\n        [ 68,  72,  77, ...,  40,  38,  40],\n        [ 65,  69,  74, ...,  39,  37,  39]],\n\n       [[ 51,  56,  60, ...,  67,  61,  56],\n        [ 55,  60,  66, ...,  71,  66,  60],\n        [ 60,  65,  71, ...,  76,  71,  66],\n        ...,\n        [ 90,  95, 100, ...,  29,  30,  29],\n        [ 86,  91,  97, ...,  28,  27,  28],\n        [ 83,  88,  93, ...,  27,  25,  27]]], dtype=uint8)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Environments import SkyRunner, MultithreadGym\n",
    "frame_stack = False\n",
    "frames = 4\n",
    "use_grayscale=False\n",
    "\n",
    "# Multithreaded environment wrapper\n",
    "env = MultithreadGym.MultithreadGym(thread_int=1, env_int=1, frame_stack=frame_stack, frames_int=frames, use_grayscale=use_grayscale)\n",
    "\n",
    "# Evaluation environment\n",
    "eval_env = SkyRunner.CustomEnv(frame_stack=frame_stack, frames_int=frames, use_grayscale=use_grayscale)\n",
    "eval_env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for ready enviornment\n",
      "Ready enviornment received\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Broken block detected. Moving to location 1\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Broken block detected. Moving to location 2\n",
      "Inventory and weather cleared!\n",
      "Broken block detected. Moving to location 3\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Broken block detected. Moving to location 4\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Broken block detected. Moving to location 5\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Broken block detected. Moving to location 6\n",
      "Inventory and weather cleared!\n",
      "Broken block detected. Moving to location 7\n",
      "Inventory and weather cleared!\n",
      "Inventory and weather cleared!\n",
      "Broken block detected. Moving to location 8\n",
      "Inventory and weather cleared!\n",
      "Broken block detected. Moving to location 9\n",
      "Inventory and weather cleared!\n",
      "Broken block detected. Moving to location 10\n",
      "Inventory and weather cleared!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [3], line 6\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m\n\u001B[1;32m      4\u001B[0m importlib\u001B[38;5;241m.\u001B[39mreload(train_openAI)\n\u001B[0;32m----> 6\u001B[0m \u001B[43mtrain_openAI\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_env\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_prioritized_replay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mOlav-init-leaves-2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/train_openAI.py:90\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(env, eval_env, name, total_timesteps, eval_freq, n_eval_episodes, learning_rate, learning_starts, buffer_size, batch_size, exploration_initial_eps, exploration_fraction, exploration_final_eps, gamma, target_update_interval, gradient_steps, tau, use_prioritized_replay, prioritized_replay_eps, prioritized_replay_initial_beta, prioritized_replay_final_beta, prioritized_replay_beta_fraction)\u001B[0m\n\u001B[1;32m     60\u001B[0m checkpoint_callback \u001B[38;5;241m=\u001B[39m CheckpointCallback(\n\u001B[1;32m     61\u001B[0m     save_freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5000\u001B[39m,\n\u001B[1;32m     62\u001B[0m     save_path\u001B[38;5;241m=\u001B[39mpath1,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m     save_vecnormalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     66\u001B[0m )\n\u001B[1;32m     68\u001B[0m model \u001B[38;5;241m=\u001B[39m DoubleDQN(\n\u001B[1;32m     69\u001B[0m     env\u001B[38;5;241m=\u001B[39menv,\n\u001B[1;32m     70\u001B[0m     policy\u001B[38;5;241m=\u001B[39mMlpPolicy,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     87\u001B[0m     prioritized_replay_final_beta\u001B[38;5;241m=\u001B[39mprioritized_replay_final_beta\n\u001B[1;32m     88\u001B[0m )\n\u001B[0;32m---> 90\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     91\u001B[0m \u001B[43m            \u001B[49m\u001B[43meval_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m            \u001B[49m\u001B[43meval_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_eval_episodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_eval_episodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheckpoint_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     98\u001B[0m path2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdDQN-checkpoints/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(path2):\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/CustomBaselines3/DoubleDQN.py:313\u001B[0m, in \u001B[0;36mDoubleDQN.learn\u001B[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;28mself\u001B[39m: DQNSelf,\n\u001B[1;32m    301\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    310\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    311\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DQNSelf:\n\u001B[0;32m--> 313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_eval_episodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_eval_episodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_log_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_log_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/venv/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:356\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.learn\u001B[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[1;32m    353\u001B[0m callback\u001B[38;5;241m.\u001B[39mon_training_start(\u001B[38;5;28mlocals\u001B[39m(), \u001B[38;5;28mglobals\u001B[39m())\n\u001B[1;32m    355\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m<\u001B[39m total_timesteps:\n\u001B[0;32m--> 356\u001B[0m     rollout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect_rollouts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m        \u001B[49m\u001B[43maction_noise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maction_noise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlearning_starts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_starts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    362\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreplay_buffer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplay_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    364\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    366\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m rollout\u001B[38;5;241m.\u001B[39mcontinue_training \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[1;32m    367\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/venv/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:589\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.collect_rollouts\u001B[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001B[0m\n\u001B[1;32m    586\u001B[0m actions, buffer_actions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sample_action(learning_starts, action_noise, env\u001B[38;5;241m.\u001B[39mnum_envs)\n\u001B[1;32m    588\u001B[0m \u001B[38;5;66;03m# Rescale and perform action\u001B[39;00m\n\u001B[0;32m--> 589\u001B[0m new_obs, rewards, dones, infos \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mnum_envs\n\u001B[1;32m    592\u001B[0m num_collected_steps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001B[0m, in \u001B[0;36mVecEnv.step\u001B[0;34m(self, actions)\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;124;03mStep the environments with the given action\u001B[39;00m\n\u001B[1;32m    157\u001B[0m \n\u001B[1;32m    158\u001B[0m \u001B[38;5;124;03m:param actions: the action\u001B[39;00m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;124;03m:return: observation, reward, done, information\u001B[39;00m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_async(actions)\n\u001B[0;32m--> 162\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001B[0m, in \u001B[0;36mDummyVecEnv.step_wait\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep_wait\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m VecEnvStepReturn:\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m env_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_envs):\n\u001B[0;32m---> 43\u001B[0m         obs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_rews[env_idx], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_dones[env_idx], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_infos[env_idx] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menvs\u001B[49m\u001B[43m[\u001B[49m\u001B[43menv_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactions\u001B[49m\u001B[43m[\u001B[49m\u001B[43menv_idx\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_dones[env_idx]:\n\u001B[1;32m     47\u001B[0m             \u001B[38;5;66;03m# save final observation where user can get it, then reset\u001B[39;00m\n\u001B[1;32m     48\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_infos[env_idx][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mterminal_observation\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m obs\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/venv/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:94\u001B[0m, in \u001B[0;36mMonitor.step\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneeds_reset:\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTried to step environment that needs reset\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 94\u001B[0m observation, reward, done, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrewards\u001B[38;5;241m.\u001B[39mappend(reward)\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m done:\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/Environments/SkyRunner.py:72\u001B[0m, in \u001B[0;36mCustomEnv.step\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, action):\n\u001B[0;32m---> 72\u001B[0m     observation, reward, done, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframe_stack:\n\u001B[1;32m     74\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframe_stack_q\u001B[38;5;241m.\u001B[39mappend(torch\u001B[38;5;241m.\u001B[39mtensor(observation))\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/Environments/Skyrunner_mission_interpreter.py:174\u001B[0m, in \u001B[0;36mMission.step\u001B[0;34m(self, num)\u001B[0m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, num):\n\u001B[1;32m    173\u001B[0m     action \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtranslate_action(num)\n\u001B[0;32m--> 174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactStep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/Environments/Skyrunner_mission_interpreter.py:167\u001B[0m, in \u001B[0;36mMission.actStep\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mactStep\u001B[39m(\u001B[38;5;28mself\u001B[39m, action):\n\u001B[1;32m    166\u001B[0m     _, __, ___, ____ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv\u001B[38;5;241m.\u001B[39mstep(action)\n\u001B[0;32m--> 167\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m__\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m___\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m____\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/Environments/Skyrunner_mission_interpreter.py:111\u001B[0m, in \u001B[0;36mMission.eval\u001B[0;34m(self, obs, reward, done, info)\u001B[0m\n\u001B[1;32m    109\u001B[0m     reward \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mREWARD_BONUS_AT_LEVEL_COMPLETE\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobs_simplify:\n\u001B[0;32m--> 111\u001B[0m     obs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrgb_simplify\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrgb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepisode \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepisode_length:\n\u001B[1;32m    113\u001B[0m     done \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Ai/IDATT2502-SkyBrainAI/Environments/Skyrunner_mission_interpreter.py:186\u001B[0m, in \u001B[0;36mMission.rgb_simplify\u001B[0;34m(self, array)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrgb_simplify\u001B[39m(\u001B[38;5;28mself\u001B[39m, array):\n\u001B[0;32m--> 186\u001B[0m     array \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor(\u001B[43marray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobs_grayscale:\n\u001B[1;32m    188\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrayscale(array)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import train_openAI\n",
    "import importlib\n",
    "\n",
    "importlib.reload(train_openAI)\n",
    "\n",
    "train_openAI.train(env, eval_env=eval_env, eval_freq=5000, use_prioritized_replay=False, name=\"Olav-init-leaves-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shutdown Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopping Reloader 0\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from CustomBaselines3.DoubleDQN import DoubleDQN\n",
    "\n",
    "_env = env\n",
    "model = DoubleDQN.load(\"/Users/kristian.aars/PycharmProjects/IDATT2502-SkyBrainAI/dDQN-checkpoints/checkpoint_30000_steps.zip\")\n",
    "\n",
    "obs = env.reset()\n",
    "acc_r = 0\n",
    "while True:\n",
    "    act, st = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(act)\n",
    "\n",
    "    acc_r += reward\n",
    "\n",
    "    env.render()\n",
    "\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        print(\"Finished with reward %d\" % acc_r)\n",
    "        acc_r = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9100f79a7cf9690ce7cf79f8b2e62e57361e326a7400229bc21352d33c935312"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
